# Introduction to Orchestration and Airflow

An overview of the world of data orchestration and Apache Airflow!

## About this Module

Welcome to the Introduction to Orchestration and Airflow Module! 

In this Module, we'll deep dive into the conceptual foundations of data orchestration. We will explore its definition and historical evolution that have led to the development of modern orchestration solutions like Apache Airflow.

Our exploration of Airflow will also focus on understanding its architecture, use cases, and the diverse personas that leverage Airflow for orchestrating complex workflows. We'll also examine the strategic considerations for deploying Airflow across various scenarios and stages of team growth. Finally, we'll go through how data pipelines are built in Airflow using Directed Acyclic Graphs (DAGs), Tasks, and Operators. 

## Learning Objectives

At the end of this module, you'll be able to:

- Define data orchestration
- Visualize the historical journey of modern data orchestration
- Define what Apache Airflow is
- Identify the key characteristics of Apache Airflow
- Identify the key personas that use Airflow and for what purpose
- Identify critical use cases for Airflow
- Identify considerations for using Airflow for specific use-cases
- Identify how Airflow is run at each stage of a growing team
- Define three key Airflow terms: DAG, Task, and Operator
- Visualize how a DAG is structured using Tasks and Operators

## Syllabus

1. Introduction
   - Welcome
3. Data Orchestration Fundamentals
   - Why Orchestration?
5. Airflow for Data Orchestration
   - Introduction to Airflow
   - Who uses Airflow and for what?
   - Considertions of using Airflow
7. Demystifying Airflow
   - Running Airflow
   - How does Airflow work?
9. Wrap Up
   - Review
   - Final Quiz
   - How was it?
